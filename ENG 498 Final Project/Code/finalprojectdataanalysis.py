# -*- coding: utf-8 -*-
"""finalProjectDataAnalysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1to0mS-MfG_4H2ed39Qil5EX6wprAYH4s
"""

from google.colab import files
uploaded = files.upload()

"""#Count number of teams that have characteristics of high possession teams, grouped by date

Since the original data set, found in the README, is too large to be on Github, I extracted the Team_Attributes CSV file for the raw data. This SQLite query can be used to extract that CSV for further examination.

```SQL
select * from Team_Attributes
```

This is the SQLite query I used to get the number of teams that played with the characteristics of high possession teams, grouped by year, from 2010 to 2015. You would use this with the raw database file in the Code folder in order to properly extract the same processed data set included in the project folder.

```SQL
select date, 
sum(case when buildupplaypassingclass = "Short" then 1 else 0 end) as ShortPassingTeams,
sum(case when chancecreationpassingclass = "Safe" then 1 else 0 end) as SafePassingTeams,
sum(case when buildupplayspeedclass = "Fast" then 1 else 0 end) as FastPassingTeams,
sum(case when defencepressureclass = "High" then 1 else 0 end) as HighPressureTeams
from Team_Attributes
group by date
```
"""

#Github repo: https://github.com/nikhilgarg7/ENG498FinalProject

#Import pandas and io in order to read the csv file

import pandas as pd
import io

team_data = pd.read_csv(io.BytesIO(uploaded['team_attribute_count.csv']))
team_data

import numpy as np

#Convert to numpy in order to manipulate further
data = team_data.to_numpy()
data = data.astype(str)
headers = np.array(list(team_data))
data

#Convert the date into just years, specific day and month isn't relevant for my data

for i in range(0, len(data)):
  data[i, 0] = data[i, 0][0:4]

data

# Convert the data from a string array to an int array that can be used for visualizations
data = data.astype(int)
data

#Convert array to int array and check for null values. Since this is a small array, it is easy to check for missing values.
empty_rows_idx = np.argwhere(a=data == "")
#condition to find
empty_rows_idx.shape

#If the test passes, the shape of the empty_rows_idx should be (0, 0)

#Import matplotlib in order to visualize the findings

import matplotlib.pyplot as plt

plt.bar(data[:, 0], data[:, 1])
plt.xlabel("Year")
plt.ylabel("Number of Short Passing Teams")
plt.title("Number of Short Passing Teams by Year")
plt.show()

plt.bar(data[:, 0], data[:, 2])
plt.xlabel("Year")
plt.ylabel("Number of Safe Passing Teams")
plt.title("Number of Safe Passing Teams by Year")
plt.show()

plt.bar(data[:, 0], data[:, 3])
plt.xlabel("Year")
plt.ylabel("Number of Fast Passing Teams")
plt.title("Number of Fast Passing Teams by Year")
plt.show()

plt.bar(data[:, 0], data[:, 4])
plt.xlabel("Year")
plt.ylabel("Number of High Pressure Teams")
plt.title("Number of High Pressure Teams by Year")
plt.show()
